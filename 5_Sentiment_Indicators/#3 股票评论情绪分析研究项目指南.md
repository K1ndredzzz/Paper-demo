# 股票评论情绪分析研究项目指南

## 一、项目概述

本项目旨在通过对8个行业111只股票2025年02.01-02.28的股吧评论数据进行情绪分析，构建有效的情绪变量，研究投资者情绪与股票市场表现的关系。研究窗口涵盖t+1、t+3、t+5三个时间点，以探索情绪指标的对股票收益的影响机制。

### 1.1 研究目标

- 通过python爬虫爬取股吧数据
- 情绪分析构建情绪指标体系
- 收集个股信息合并股票情绪行情面板数据
- 回归分析探究不同维度情绪指标对股票收益的影响机制

## 二、环境配置

### 2.1 硬件提供

- CPU: 5600
- RAM: 16GB
- GPU: RTX 3050
- 云服务器: 阿里云

### 2.2 软件依赖

Windows 10, python 3.11.9

# 安装必要库
pip install pandas numpy matplotlib seaborn scikit-learn
pip install torch torchvision
pip install transformers datasets
pip install jieba
pip install akshare
pip install statsmodels scipy linearmodels
pip install gensim
pip install tqdm
```



## 三、数据准备

### 3.1 评论数据预处理

```python
# 评论数据预处理示例代码
import pandas as pd
import re
import jieba

def preprocess_comments(raw_data_path, output_path):
    # 读取原始评论数据
    df = pd.read_csv(raw_data_path, encoding='utf-8')
    
    # 数据清洗
    df['clean_comment'] = df['comment'].apply(lambda x: re.sub(r'[^\w\s]', '', str(x)))
    df['clean_comment'] = df['clean_comment'].apply(lambda x: re.sub(r'\s+', ' ', x.strip()))
    
    # 广告过滤
    ad_keywords = ['开户', '加微信', '加QQ', '电报群', '推荐股', '老师', '信号', '指导', 
                  '带飞', '操作建议', '直播间', '免费分析', '牛股', '加我', '联系我']
    
    def filter_ads(text):
        for keyword in ad_keywords:
            if keyword in text:
                return True
        return False
    
    # 过滤广告和短内容
    df = df[~df['clean_comment'].apply(filter_ads)]
    df = df[df['clean_comment'].str.len() >= 5]
    
    # 保存处理后的数据
    df.to_csv(output_path, index=False, encoding='utf-8')
    
    return df
```



### 3.2 股票市场数据获取(2025.02.01-02.28) (通过akshare)

```python
# 股票价格数据获取示例代码
import akshare as ak
import pandas as pd
from tqdm import tqdm
import time

def get_stock_data_akshare(stock_codes, start_date, end_date):
    """使用akshare获取股票数据"""
    all_data = []
    
    for code in tqdm(stock_codes, desc="获取股票数据"):
        try:
            # 获取日K线数据
            df = ak.stock_zh_a_hist(symbol=code, period="daily", 
                                    start_date=start_date, end_date=end_date, 
                                    adjust="qfq")
            
            # 重命名列以统一格式
            df.rename(columns={
                '日期': 'date',
                '开盘': 'open',
                '收盘': 'close',
                '最高': 'high',
                '最低': 'low',
                '成交量': 'volume',
                '成交额': 'amount',
                '振幅': 'amplitude',
                '涨跌幅': 'pct_change',
                '涨跌额': 'price_change',
                '换手率': 'turnover_rate'
            }, inplace=True)
            
            # 添加股票代码
            df['code'] = code
            all_data.append(df)
            
            # 避免频繁请求被限制
            time.sleep(0.5)
            
        except Exception as e:
            print(f"获取股票 {code} 数据时出错: {e}")
    
    # 合并所有股票数据
    if all_data:
        stock_data = pd.concat(all_data, ignore_index=True)
        
        # 确保日期格式一致
        stock_data['date'] = pd.to_datetime(stock_data['date'])
        
        # 计算收益率
        stock_data = stock_data.sort_values(['code', 'date'])
        # 向前计算收益率（未来收益率）
        stock_data['forward_ret_1d'] = stock_data.groupby('code')['close'].shift(-1).div(stock_data['close']) - 1
        stock_data['forward_ret_3d'] = stock_data.groupby('code')['close'].shift(-3).div(stock_data['close']) - 1
        stock_data['forward_ret_5d'] = stock_data.groupby('code')['close'].shift(-5).div(stock_data['close']) - 1

        
        return stock_data
    else:
        raise ValueError("未能获取任何股票数据")


def get_index_data_akshare(index_codes, start_date, end_date):
    """使用akshare获取申万行业指数数据"""
    all_data = []
    
    for code in tqdm(index_codes, desc="获取行业指数数据"):
        try:
            # 获取申万行业指数数据
            df = ak.index_hist_sw(symbol=code, start_date=start_date, end_date=end_date)
            
            # 重命名列以统一格式
            df.rename(columns={
                '日期': 'date',
                '开盘': 'idx_open',
                '收盘': 'idx_close',
                '最高': 'idx_high',
                '最低': 'idx_low',
                '成交量': 'idx_volume',
                '成交额': 'idx_amount'
            }, inplace=True)
            
            # 添加指数代码
            df['index_code'] = code
            all_data.append(df)
            
            # 避免频繁请求被限制
            time.sleep(0.5)
            
        except Exception as e:
            print(f"获取行业指数 {code} 数据时出错: {e}")
    
    # 合并所有指数数据
    if all_data:
        index_data = pd.concat(all_data, ignore_index=True)
        index_data['date'] = pd.to_datetime(index_data['date'])
        return index_data
    else:
        raise ValueError("未能获取任何行业指数数据")


def load_industry_mapping():
    """从industries.py加载行业映射关系"""
    import re
    
    industry_map = []
    
    with open('industries.py', 'r', encoding='utf-8') as f:
        content = f.read()
        
    # 使用正则表达式提取各个行业及对应的股票代码
    industry_sections = re.split(r'##\s+', content)[1:]  # 跳过文件开头
    
    for section in industry_sections:
        lines = section.strip().split('\n')
        industry_name = lines[0].strip()
        
        # 提取该行业下的所有股票代码
        stock_codes = []
        for line in lines[1:]:
            if '|' in line:  # 表格行
                parts = line.split('|')
                if len(parts) >= 3:  # 确保有足够的列
                    code = parts[1].strip()
                    if re.match(r'^\d{6}$', code):  # 确保是6位数字的股票代码
                        stock_codes.append(code)
        
        if stock_codes:
            for code in stock_codes:
                industry_map.append({
                    'code': code,
                    'industry': industry_name
                })
    
    return pd.DataFrame(industry_map)
```



### 3.3 行业数据整理

```python
def organize_industry_data(stock_data, industry_mapping=None):
    """整理行业数据，合并行业信息"""
    if industry_mapping is None:
        # 如果没有提供行业映射，尝试从industries.py加载
        industry_mapping = load_industry_mapping()
    elif isinstance(industry_mapping, str):
        # 如果提供了文件路径，从文件加载
        industry_mapping = pd.read_csv(industry_mapping)
    
    # 合并行业信息
    stock_data = pd.merge(stock_data, industry_mapping[['code', 'industry']], on='code', how='left')
    
    # 处理行业缺失值
    stock_data['industry'] = stock_data['industry'].fillna('未知')
    
    return stock_data
```



## 四、情绪分析模型构建

### 4.1 ModelScope情感分析模型

```python
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
import numpy as np
import pandas as pd
from tqdm import tqdm

class StructBERTSentimentAnalyzer:
    def __init__(self, model_id='iic/nlp_structbert_sentiment-classification_chinese-large'):
        """
        初始化StructBERT情感分析器
        
        Args:
            model_id (str): ModelScope模型ID
                默认使用'iic/nlp_structbert_sentiment-classification_chinese-large'
                可选值:
                - 'iic/nlp_structbert_sentiment-classification_chinese-large': 大模型版本
                - 'iic/nlp_structbert_sentiment-classification_chinese-tiny': 小模型版本
        """
        self.semantic_cls = pipeline(Tasks.text_classification, model_id)
        # 情感标签映射 (负面:-1, 正面:1)
        self.label_map = {"负面": -1, "正面": 1}
    
    def predict_sentiment(self, text):
        """预测单条文本的情感"""
        try:
            # 调用ModelScope API
            result = self.semantic_cls(input=text)
            
            if result['Success'] and result['Code'] == 200:
                data = result['Data']
                labels = data['labels']
                scores = data['scores']
                
                # 找出正面和负面标签的索引
                positive_idx = labels.index('正面') if '正面' in labels else None
                negative_idx = labels.index('负面') if '负面' in labels else None
                
                if positive_idx is not None and negative_idx is not None:
                    positive_prob = scores[positive_idx]
                    negative_prob = scores[negative_idx]
                    
                    # 确定极性 (概率更高的标签作为预测结果)
                    if positive_prob > negative_prob:
                        polarity = self.label_map["正面"]  # 1
                    else:
                        polarity = self.label_map["负面"]  # -1
                    
                    # 计算情感得分 (正面概率 - 负面概率)
                    score = positive_prob - negative_prob
                    
                    # 计算情感强度 (最高概率与次高概率的差距)
                    intensity = abs(positive_prob - negative_prob)
                    
                    return {
                        'score': float(score),
                        'polarity': int(polarity),
                        'intensity': float(intensity),
                        'positive_prob': float(positive_prob),
                        'negative_prob': float(negative_prob),
                        'success': True
                    }
            
            # API调用失败或解析错误时返回默认值
            return {
                'score': 0.0,
                'polarity': 0,
                'intensity': 0.0,
                'positive_prob': 0.5,
                'negative_prob': 0.5,
                'success': False
            }
            
        except Exception as e:
            print(f"预测出错: {e}")
            return {
                'score': 0.0,
                'polarity': 0,
                'intensity': 0.0,
                'positive_prob': 0.5,
                'negative_prob': 0.5,
                'success': False
            }
    
    def predict_batch(self, texts, batch_size=32):
        """批量预测多条文本的情感"""
        results = []
        
        for i in tqdm(range(0, len(texts), batch_size), desc="情感分析进度"):
            batch_texts = texts[i:i+batch_size]
            batch_results = []
            
            for text in batch_texts:
                batch_results.append(self.predict_sentiment(text))
            
            results.extend(batch_results)
        
        return results
    
    def analyze_sentiment_statistics(self, sentiment_results):
        """
        对情感分析结果进行统计分析
        
        Args:
            sentiment_results: 情感分析结果列表
            
        Returns:
            统计信息字典
        """
        # 提取成功的预测结果
        valid_results = [r for r in sentiment_results if r['success']]
        
        if not valid_results:
            return {
                "总评论数": len(sentiment_results),
                "有效分析数": 0,
                "分析成功率": 0.0
            }
        
        # 提取各项指标值
        polarities = [r['polarity'] for r in valid_results]
        scores = [r['score'] for r in valid_results]
        intensities = [r['intensity'] for r in valid_results]
        
        # 统计极性分布
        positive_count = polarities.count(1)
        negative_count = polarities.count(-1)
        
        # 计算统计指标
        stats = {
            "总评论数": len(sentiment_results),
            "有效分析数": len(valid_results),
            "分析成功率": len(valid_results) / len(sentiment_results) * 100,
            "正面评论数": positive_count,
            "负面评论数": negative_count,
            "正面评论比例": positive_count / len(valid_results) * 100,
            "负面评论比例": negative_count / len(valid_results) * 100,
            "平均情感得分": np.mean(scores),
            "情感得分中位数": np.median(scores),
            "情感得分标准差": np.std(scores),
            "平均情感强度": np.mean(intensities),
            "最大情感强度": max(intensities),
            "最小情感强度": min(intensities)
        }
        
        return stats
```

### 4.2 应用情感分析模型

```python
def apply_sentiment_analysis(comments_df, analyzer):
    """
    对评论数据应用情感分析模型
    
    Args:
        comments_df: 包含评论的DataFrame
        analyzer: 情感分析器实例
    
    Returns:
        添加了情感分析结果的DataFrame
    """
    # 获取评论文本列表
    comments = comments_df['clean_comment'].tolist()
    
    # 批量进行情感分析
    print("开始情感分析...")
    sentiment_results = analyzer.predict_batch(comments)
    
    # 计算情感统计信息
    stats = analyzer.analyze_sentiment_statistics(sentiment_results)
    print("\n=== 情感分析统计信息 ===")
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"{key}: {value:.2f}")
        else:
            print(f"{key}: {value}")
    
    # 将情感分析结果添加到DataFrame
    comments_df['sentiment_score'] = [r['score'] for r in sentiment_results]
    comments_df['sentiment_polarity'] = [r['polarity'] for r in sentiment_results]
    comments_df['sentiment_intensity'] = [r['intensity'] for r in sentiment_results]
    comments_df['positive_prob'] = [r['positive_prob'] for r in sentiment_results]
    comments_df['negative_prob'] = [r['negative_prob'] for r in sentiment_results]
    
    return comments_df
```

### 4.3 情感分布可视化

```python
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_sentiment_distribution(comments_with_sentiment, output_path='sentiment_distribution.png'):
    """
    可视化情感分布
    
    Args:
        comments_with_sentiment: 带有情感分析结果的DataFrame
        output_path: 输出图片路径
    """
    # 设置中文字体
    try:
        plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
        plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号
    except:
        print("警告: 未能正确设置中文字体，图表中的中文可能无法正确显示")
    
    # 创建图表
    plt.figure(figsize=(10, 8))
    
    # 绘制情感得分直方图
    plt.subplot(2, 1, 1)
    sns.histplot(comments_with_sentiment['sentiment_score'], kde=True, bins=30)
    plt.title('评论情感得分分布')
    plt.xlabel('情感得分')
    plt.ylabel('频率')
    
    # 绘制情感极性饼图
    plt.subplot(2, 2, 3)
    polarity_counts = comments_with_sentiment['sentiment_polarity'].value_counts()
    labels = ['负面' if p == -1 else '正面' if p == 1 else '中性' for p in polarity_counts.index]
    plt.pie(polarity_counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#FF9999', '#99FF99'])
    plt.axis('equal')
    plt.title('情感极性分布')
    
    # 绘制情感强度箱线图
    plt.subplot(2, 2, 4)
    sns.boxplot(x='sentiment_polarity', y='sentiment_intensity', 
                data=comments_with_sentiment[comments_with_sentiment['sentiment_polarity'] != 0])
    plt.xticks([-1, 1], ['负面', '正面'])
    plt.title('不同极性的情感强度分布')
    plt.xlabel('情感极性')
    plt.ylabel('情感强度')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"情感分布图表已保存至: {output_path}")
```

### 4.4 情感分析结果整合

```python
def aggregate_sentiment_by_stock(comments_with_sentiment):
    """
    按股票代码整合情感分析结果
    
    Args:
        comments_with_sentiment: 带有情感分析结果的DataFrame
        
    Returns:
        按股票和日期汇总的情感指标DataFrame
    """
    # 按股票代码和日期分组
    grouped = comments_with_sentiment.groupby(['stock_code', 'date'])
    
    # 计算汇总指标
    sentiment_summary = grouped.agg(
        avg_score=('sentiment_score', 'mean'),
        sentiment_std=('sentiment_score', 'std'),
        positive_ratio=('sentiment_polarity', lambda x: sum(x == 1) / len(x) if len(x) > 0 else 0),
        negative_ratio=('sentiment_polarity', lambda x: sum(x == -1) / len(x) if len(x) > 0 else 0),
        avg_intensity=('sentiment_intensity', 'mean'),
        comment_count=('sentiment_score', 'count')
    ).reset_index()
    
    # 计算情感净值
    sentiment_summary['sentiment_net'] = sentiment_summary['positive_ratio'] - sentiment_summary['negative_ratio']
    
    # 填充可能的缺失值
    sentiment_summary = sentiment_summary.fillna({
        'sentiment_std': 0,
        'avg_intensity': 0
    })
    
    return sentiment_summary
```



## 五、情绪指标构建

```python
def build_sentiment_indicators(sentiment_results_path, merged_market_path, output_dir='./output'):
    """
    构建个股和行业层面的情绪指标，并输出为两个CSV文件
    
    Args:
        sentiment_results_path (str): 情感分析结果文件路径
        merged_market_path (str): 合并市场数据文件路径
        output_dir (str): 输出目录
    
    Returns:
        tuple: (个股数据文件路径, 行业数据文件路径)
    """
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # 读取原始数据
    sentiment_df = pd.read_csv(sentiment_results_path)
    market_df = pd.read_csv(merged_market_path)
    
    # 确保日期格式一致
    for df in [sentiment_df, market_df]:
        df['date'] = pd.to_datetime(df['date'])
    
    # 1. 构建个股日度数据
    print("构建个股情绪指标...")
    stock_daily_data = calculate_stock_level_indicators(sentiment_df, market_df)
    
    # 2. 构建行业日度数据
    print("构建行业情绪指标...")
    industry_daily_data = calculate_industry_level_indicators(stock_daily_data, market_df)
    
    # 保存结果
    stock_output_path = os.path.join(output_dir, 'stock_daily_sentiment.csv')
    industry_output_path = os.path.join(output_dir, 'industry_daily_sentiment.csv')
    
    stock_daily_data.to_csv(stock_output_path, index=False)
    industry_daily_data.to_csv(industry_output_path, index=False)
    
    print(f"个股数据已保存至: {stock_output_path}")
    print(f"行业数据已保存至: {industry_output_path}")
    
    return stock_output_path, industry_output_path

def calculate_stock_level_indicators(sentiment_df, market_df):
    """计算个股层面的情绪指标"""
    # 按股票和日期分组计算情绪指标
    stock_sentiment = sentiment_df.groupby(['stock_code', 'date']).agg(
        avg_sentiment=('sentiment_score', 'mean'),
        sentiment_std=('sentiment_score', 'std'),
        positive_ratio=('sentiment_polarity', lambda x: sum(x == 1) / len(x) if len(x) > 0 else 0),
        negative_ratio=('sentiment_polarity', lambda x: sum(x == -1) / len(x) if len(x) > 0 else 0),
        avg_intensity=('sentiment_intensity', 'mean'),
        comment_count=('sentiment_score', 'count'),
        avg_positive_prob=('positive_prob', 'mean'),
        avg_negative_prob=('negative_prob', 'mean')
    ).reset_index()
    
    # 计算情绪净值和一致性
    stock_sentiment['sentiment_net'] = stock_sentiment['positive_ratio'] - stock_sentiment['negative_ratio']
    stock_sentiment['sentiment_consensus'] = 1 - stock_sentiment[['positive_ratio', 'negative_ratio']].std(axis=1)
    
    # 按股票分组计算动量指标
    grouped = stock_sentiment.sort_values(['stock_code', 'date']).groupby('stock_code')
    
    # 添加动量指标
    for window in [3, 5, 10]:
        stock_sentiment[f'ma_{window}d'] = grouped['avg_sentiment'].rolling(window).mean()
        stock_sentiment[f'std_{window}d'] = grouped['avg_sentiment'].rolling(window).std()
        stock_sentiment[f'sentiment_change_{window}d'] = grouped['avg_sentiment'].pct_change(window)
    
    # 合并市场数据
    stock_daily = pd.merge(
        stock_sentiment,
        market_df[[
            'stock_code', 'date', 'open', 'close', 'high', 'low', 
            'volume', 'amount', 'amplitude', 'pct_change', 'price_change',
            'turnover_rate', 'forward_ret_1d', 'forward_ret_3d', 'forward_ret_5d',
            'industry', 'board_code'
        ]],
        on=['stock_code', 'date'],
        how='left'
    )
    
    return stock_daily

def calculate_industry_level_indicators(stock_daily, market_df):
    """计算行业层面的情绪指标"""
    # 按行业和日期分组计算行业情绪指标
    industry_daily = stock_daily.groupby(['board_code', 'date']).agg(
        # 情绪指标
        ind_avg_sentiment=('avg_sentiment', 'mean'),
        ind_sentiment_std=('avg_sentiment', 'std'),
        ind_positive_ratio=('positive_ratio', 'mean'),
        ind_negative_ratio=('negative_ratio', 'mean'),
        ind_sentiment_net=('sentiment_net', 'mean'),
        ind_sentiment_consensus=('sentiment_consensus', 'mean'),
        
        # 交易指标
        ind_avg_turnover=('turnover_rate', 'mean'),
        ind_total_volume=('volume', 'sum'),
        ind_total_amount=('amount', 'sum'),
        
        # 股票覆盖
        stock_count=('stock_code', 'nunique'),
        total_comments=('comment_count', 'sum')
    ).reset_index()
    
    # 计算行业情绪分散度
    industry_daily['sentiment_dispersion'] = industry_daily['ind_sentiment_std'] / abs(industry_daily['ind_avg_sentiment'])
    
    # 合并行业指数数据
    industry_daily = pd.merge(
        industry_daily,
        market_df[[
            'date', 'board_code', 'idx_close', 'idx_open', 'idx_high', 'idx_low',
            'idx_volume', 'idx_amount', 'idx_pct_change'
        ]].drop_duplicates(),
        on=['date', 'board_code'],
        how='left'
    )
    
    # 计算行业情绪动量
    grouped = industry_daily.sort_values(['board_code', 'date']).groupby('board_code')
    
    for window in [3, 5, 10]:
        industry_daily[f'ind_ma_{window}d'] = grouped['ind_avg_sentiment'].rolling(window).mean()
        industry_daily[f'ind_sentiment_change_{window}d'] = grouped['ind_avg_sentiment'].pct_change(window)
    
    return industry_daily
```

使用示例：
```python
# 生成分析用数据文件
stock_file, industry_file = build_sentiment_indicators(
    'sentiment_results.csv',
    'merged_stock_industry_index.csv',
    './output'
)

# 输出文件格式预览
stock_daily = pd.read_csv(stock_file)
industry_daily = pd.read_csv(industry_file)

print("\n个股数据包含字段:")
print(stock_daily.columns.tolist())

print("\n行业数据包含字段:")
print(industry_daily.columns.tolist())
```



## 六、实证分析

### 6.1 面板数据分析

```python:/src/analysis/panel_regression.py
import pandas as pd
import numpy as np
import statsmodels.api as sm
from linearmodels import PanelOLS
from typing import Dict, List, Optional

class PanelRegressionAnalyzer:
    def __init__(self, data: pd.DataFrame):
        """
        初始化面板数据分析器
        
        Args:
            data: 包含股票代码、日期和其他变量的DataFrame
        """
        self.raw_data = data.copy()
        self._validate_data()
        self.panel_data = self._prepare_panel_data()
        
    def _validate_data(self) -> None:
        """验证输入数据的完整性"""
        required_cols = ['stock_code', 'date', 'ret_1d', 'ret_3d', 'ret_5d']
        missing_cols = [col for col in required_cols if col not in self.raw_data.columns]
        if missing_cols:
            raise ValueError(f"数据缺少必需列: {missing_cols}")
    
    def _prepare_panel_data(self) -> pd.DataFrame:
        """准备面板数据"""
        return self.raw_data.set_index(['stock_code', 'date'])
    
    def run_analysis(self, 
                    sentiment_vars: Optional[List[str]] = None,
                    control_vars: Optional[List[str]] = None) -> Dict:
        """
        执行面板回归分析
        
        Args:
            sentiment_vars: 情绪变量列表
            control_vars: 控制变量列表
        
        Returns:
            包含不同模型结果的字典
        """
        # 设置默认变量
        sentiment_vars = sentiment_vars or [
            'avg_score', 'sentiment_net', 'sentiment_consensus',
            'score_change', 'cum_score_3d', 'score_zscore_5d'
        ]
        control_vars = control_vars or ['turnover_rate', 'pct_change']
        
        # 合并所有变量
        all_vars = sentiment_vars + control_vars
        
        # 验证变量存在性
        missing_vars = [var for var in all_vars if var not in self.panel_data.columns]
        if missing_vars:
            raise ValueError(f"数据中缺少以下变量: {missing_vars}")
            
        # 存储模型结果
        models = {}
        
        # 对每个预测期限进行分析
        for horizon, target in [('ret_1d', 't+1'), ('ret_3d', 't+3'), ('ret_5d', 't+5')]:
            try:
                # 基本模型
                exog = sm.add_constant(self.panel_data[all_vars].fillna(0))
                mod = PanelOLS(self.panel_data[horizon], exog)
                models[f'基本模型_{target}'] = mod.fit()
                
                # 实体固定效应
                mod_entity = PanelOLS(
                    self.panel_data[horizon], 
                    self.panel_data[all_vars].fillna(0),
                    entity_effects=True
                )
                models[f'股票固定效应_{target}'] = mod_entity.fit()
                
                # 双向固定效应
                mod_both = PanelOLS(
                    self.panel_data[horizon],
                    self.panel_data[all_vars].fillna(0),
                    entity_effects=True,
                    time_effects=True
                )
                models[f'双向固定效应_{target}'] = mod_both.fit()
                
            except Exception as e:
                print(f"警告: {target}期限回归失败: {str(e)}")
                continue
        
        return models
```

```stata
cd D:\Code_new\Paper\6_Stata_Reg\StructBERT_large
import delimited "D:\Code_new\Paper\6_Stata_Reg\StructBERT_large\stock_daily_sentiment.csv", clear

/**************************数据整理**************************/
encode date ,gen(time)
xtset stock_code time

//drop negative_ratio avg_positive_prob avg_negative_prob sentiment_net open high low ma_5d std_5d sentiment_change_5d ma_10d std_10d sentiment_change_10d


/*描述性统计*/
asdoc summarize, save(描述性统计_相关性分析_多重共线性检验_F检验_Hausman检验_1d.doc) replace

/*单位根检验*/
// Fisher检验
xtunitroot fisher forward_ret_1d, dfuller lags(2)
xtunitroot fisher avg_sentiment, dfuller lags(2)
// 或使用IPS检验
xtunitroot ips forward_ret_1d, lags(2)
xtunitroot ips avg_sentiment, lags(2)

/*协整检验*/
xtcointtest kao forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus

/*相关性分析*/
asdoc pwcorr forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate,sig star(.05)

/*多重共线性检验*/
reg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate, r
asdoc vif


/**************************模型选择检验**************************/
//混合效应模型
reg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate
est store ols
//随机效应模型
xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate, re
est store re
//固定效应模型
asdoc xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate, fe
est store fe
//F检验(固定效应vs混合OLS)检验个体固定效应 ，F检验表明个体固定效应优于混合ols模型 ，p<0.05表示个体效应显著，固定效应更好
asdoc hausman fe re
//Hausman检验(固定效应vs随机效应)，结果拒绝原假设，选用固定效应模型 p<0.05固定效应，大于0.05 随机效应

/*检验结果，应该选择固定效应回归分析*/


/**************************主要实证结果**************************/
//固定个体效应
xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate, fe
est store FE_Entity
//固定个体&时间效应
xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time
//固定个体效应加行业
xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate idx_close idx_volume idx_amount idx_pct_change, fe
est store FE_Entity_IND
//固定个体&时间效应加行业
xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate idx_close idx_volume idx_amount idx_pct_change i.time, fe
est store FE_Entity_Time_IND

reg2docx FE_Entity FE_Entity_Time FE_Entity_IND FE_Entity_Time_IND using Regression_1d.docx,replace b(%12.4f)t(%12.4f)drop(*.time)scalars(N r2 F)title(PanelReg_1)note(***p<0.01，**p<0.05，*p<0.10)


/**************************机制分析**************************/
/*
//交易量、交易额、换手率
qui xtreg volume avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close amplitude pct_change price_change i.time, fe
est store VOL
qui xtreg amount avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amplitude pct_change price_change i.time, fe
est store AMO
qui xtreg turnover_rate avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amplitude pct_change price_change i.time, fe
est store TR
reg2docx VOL AMO TR using Regression_1d.docx,append b(%12.4f)t(%12.4f)drop(*.time)scalars(N r2 F)title(交易量、交易额、换手率)note(***p<0.01，**p<0.05，*p<0.10)
*/


/**************************异质性分析**************************/
/*分行业回归*/
levelsof board_code, local(boards)

foreach i in `boards' {
    quietly xtreg forward_ret_1d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time if board_code==`i', fe
    estimates store Industry_`i'
}

local estlist ""
foreach i in `boards' {
    local estlist "`estlist' Industry_`i'"
}

reg2docx `estlist' using regression_1d.docx, append b(%9.3f) t(%9.3f) drop(*.time) scalars(N r2 F) title(分行业回归) note(***p<0.01，**p<0.05，*p<0.10)


/**************************内生性处理**************************/
//工具变量法
/*ivregress 2sls forward_ret_1d (avg_sentiment=L.avg_sentiment L2.avg_sentiment L3.avg_sentiment) sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.stock_code i.time, first cluster(stock_code)
est store IV
reg2docx IV using regression_1d.docx, append b(%12.4f)t(%12.4f)drop(*.stock_code *.time)scalars(N r2 F)title(IV)note(***p<0.01，**p<0.05，*p<0.10)*/
//Granger因果检验
pvar2 forward_ret_1d avg_sentiment ,lag(3) soc
xtgcause forward_ret_1d avg_sentiment, lags(2)
//pvar2 forward_ret_1d avg_sentiment ,lag(2) granger


/**************************稳健性检验**************************/
/*替换解释变量*/
//positive_ratio
xtreg forward_ret_1d positive_ratio sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_PR
//ma_3d
xtreg forward_ret_1d ma_3d std_3d sentiment_change_3d avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_ma_3d
//ma_3d
xtreg forward_ret_1d ma_5d std_5d sentiment_change_5d avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_ma_5d
reg2docx FE_Entity_Time FE_Entity_Time_PR FE_Entity_Time_ma_3d FE_Entity_Time_ma_5d using Regression_1d.docx,append b(%12.4f)t(%12.4f)drop(*.time)scalars(N r2 F)title(positive_ratio与ma_3d对比avg_sentiment)note(***p<0.01，**p<0.05，*p<0.10)
/*替换被解释变量*/
//3d
xtreg forward_ret_3d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_3d
//5d
xtreg forward_ret_5d avg_sentiment sentiment_std avg_intensity comment_count sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_5d
reg2docx FE_Entity_Time FE_Entity_Time_3d FE_Entity_Time_5d using Regression_1d.docx,append b(%12.4f)t(%12.4f)drop(*.time)scalars(N r2 F)title(ret_3/5d对比1d)note(***p<0.01，**p<0.05，*p<0.10)
/*
//滞后1期
xtreg forward_ret_1d L.avg_sentiment L.sentiment_std L.avg_intensity L.comment_count L.sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_1
//滞后2期
xtreg forward_ret_1d L2.forward_ret_1d L2.avg_sentiment L2.sentiment_std L2.avg_intensity L2.comment_count L2.sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_2
//滞后3期
xtreg forward_ret_1d L2.forward_ret_1d L3.forward_ret_1d L3.avg_sentiment L3.sentiment_std L3.avg_intensity L3.comment_count L3.sentiment_consensus close volume amount amplitude pct_change price_change turnover_rate i.time, fe
est store FE_Entity_Time_3
reg2docx FE_Entity FE_Entity_Time FE_Entity_Time_1 FE_Entity_Time_2 FE_Entity_Time_3 using Regression_1d.docx,replace b(%12.4f)t(%12.4f)drop(*.time)scalars(N r2 F)title(PanelReg_1)note(***p<0.01，**p<0.05，*p<0.10)
*/
```


* **研究目标：**  构建情绪变量，研究投资者情绪对未来股票收益（t+1, t+3, t+5）的影响。
* **数据类型：** 面板数据（Panel Data），包含多个股票在一段时间内的每日数据。
* **关键变量：**
    * **自变量（情绪变量）：** 您通过情绪分析得到的各种情绪指标，如 `avg_sentiment`, `sentiment_std`, `negative_ratio`, `positive_ratio`, `avg_intensity`, `comment_count`, `avg_positive_prob`, `avg_negative_prob` 等。
    * **因变量（股票市场表现）：**  `forward_ret_1d`, `forward_ret_3d`, `forward_ret_5d` （未来收益率）。
    * **控制变量：**  市场数据和技术指标，如 `open`, `close`, `high`, `low`, `volume`, `amount`, `amplitude`, `pct_change`, `price_change`, `turnover_rate` 以及行业 (`industry`) 和板块 (`board_code`) 等。

**1. 线性回归模型 (Linear Regression Models)**

* **普通最小二乘法 (OLS) 回归:**  这是最基础的回归模型，可以作为基准模型。您可以分别对 t+1, t+3, t+5 的未来收益率进行回归。
    * **模型形式:**  `forward_ret_t = β₀ + β₁ * sentiment_variables + β₂ * control_variables + ε`
    * **优点:**  简单易懂，易于实现和解释。
    * **缺点:**  可能无法捕捉非线性关系，且未充分利用面板数据的结构。可能存在内生性问题和遗漏变量偏差。
    * **建议:**  作为初步探索和基准模型，了解情绪变量的大致影响方向。

* **固定效应模型 (Fixed Effects Model):**  考虑到股票个体差异和行业差异，固定效应模型可以控制不随时间变化的个体效应（例如，股票本身的特质，行业特性）。
    * **模型形式:**  `forward_ret_it = β₀ + β₁ * sentiment_variables_it + β₂ * control_variables_it + αᵢ + ε_it`
        * `αᵢ` 代表个体固定效应（例如，股票 i 的固定效应）。
    * **优点:**  可以有效控制个体层面的遗漏变量偏差，提高模型估计的准确性。
    * **缺点:**  无法估计不随时间变化的变量的影响（例如，如果行业情绪在整个研究期间基本不变，行业固定效应会吸收这部分影响），并且假设个体效应与解释变量不相关。
    * **建议:**  非常适合您的面板数据，可以有效控制股票和行业层面的固定效应。您可以分别加入股票固定效应和行业固定效应，或者同时加入。

* **随机效应模型 (Random Effects Model):**  如果认为个体效应是随机的，且与解释变量不相关，可以考虑随机效应模型。
    * **模型形式:**  `forward_ret_it = β₀ + β₁ * sentiment_variables_it + β₂ * control_variables_it + υᵢ + ε_it`
        * `υᵢ` 代表随机个体效应，被视为误差项的一部分。
    * **优点:**  可以估计时不变变量的影响，并且相比固定效应模型，自由度更高，效率可能更高。
    * **缺点:**  严格假设个体效应与解释变量不相关，如果这个假设不成立，会导致模型估计有偏误。
    * **建议:**  可以使用 Hausman 检验来判断应该使用固定效应模型还是随机效应模型。通常在金融研究中，固定效应模型更为常用，因为股票个体效应很可能与解释变量相关。

**2. 考虑时间效应的模型**

* **带有时间固定效应的面板模型:**  除了个体固定效应，还可以考虑加入时间固定效应，以控制宏观经济环境或市场整体情绪等随时间变化但不随个体变化的因素。
    * **模型形式:**  `forward_ret_it = β₀ + β₁ * sentiment_variables_it + β₂ * control_variables_it + αᵢ + γₜ + ε_it`
        * `γₜ` 代表时间固定效应（例如，日期 t 的固定效应）。
    * **优点:**  进一步控制了随时间变化的共同因素的影响，提高模型稳健性。
    * **建议:**  在您的研究中，加入时间固定效应可能有助于控制市场整体情绪波动或其他宏观因素的影响。